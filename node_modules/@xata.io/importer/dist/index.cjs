'use strict';

var client = require('@xata.io/client');
var AnyDateParser = require('any-date-parser');
var CSV = require('papaparse');
var pick = require('lodash.pick');
var JSON$1 = require('json5');
var chunkArray = require('lodash.chunk');
var PQueue = require('p-queue');
var faker = require('@faker-js/faker');
var zod = require('zod');

const EMAIL_REGEX = /^[a-zA-Z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/;
function isValidEmail(email) {
  return EMAIL_REGEX.test(email);
}

function isDefined(value) {
  return value !== void 0 && value !== null;
}
function isObject(value) {
  return isDefined(value) && typeof value === "object";
}
function isString(value) {
  return typeof value === "string";
}
function notEmpty(value) {
  return value !== null && value !== void 0;
}
function compact(arr) {
  return arr.filter(notEmpty);
}
function isXataFile(value) {
  return isObject(value) && value.base64Content !== void 0;
}
function partition(array, predicate) {
  return array.reduce(
    (acc, item) => {
      acc[predicate(item) ? 0 : 1].push(item);
      return acc;
    },
    [[], []]
  );
}

const anyToDate = AnyDateParser.exportAsFunctionAny();
const isInteger = (value) => /^[-]?\d+$/.test(String(value).trim());
const isFloat = (value) => /^[-]?\d+(\.\d*)?$/.test(String(value).trim());
const isDateTime = (value) => anyToDate(value).invalid === void 0;
const isBoolean = (value, toBoolean) => {
  const toBooleanValue = toBoolean(value);
  return isDefined(toBooleanValue) && [true, false].includes(toBooleanValue);
};
const isEmail = (value) => isValidEmail(String(value).trim());
const isText = (value) => (
  // Check for newlines
  String(value).indexOf("\n") >= 0 || // Check for long strings
  String(value).length > 180
);
const tryIsJsonArray = (string) => {
  try {
    const parsed = JSON.parse(string);
    return parsed.length > 0 && Array.isArray(parsed);
  } catch (_error) {
    return false;
  }
};
const tryIsCsvArray = (string) => {
  try {
    return CSV.parse(string, { header: false }).errors.length === 0;
  } catch (_error) {
    return false;
  }
};
const parseMultiple = (value) => {
  if (tryIsJsonArray(value)) {
    return JSON.parse(value);
  }
  return CSV.parse(value, { header: false }).data[0];
};
const isGuessableMultiple = (value) => Array.isArray(value) || tryIsJsonArray(String(value));
const isGuessableVectorColumn = (values) => {
  const checks = values.map((value) => {
    const isMultiple2 = isGuessableMultiple(value);
    if (!isMultiple2)
      return null;
    const array = parseMultiple(String(value)) ?? [];
    if (array.some((item) => !isFloat(item)))
      return null;
    return array.length;
  });
  return checks.every((length) => length !== null && length > 50);
};
const isMultiple = (value) => isGuessableMultiple(value) || tryIsCsvArray(String(value));
const isMaybeMultiple = (value) => isMultiple(value) || typeof value === "string";
const isDataUri = (value) => isString(value) && /(data:.*?;base64,.*?(?:[;,|]|$))/g.test(value);
const defaultIsNull = (value) => {
  return !isDefined(value) || String(value).toLowerCase() === "null" || String(value).trim() === "";
};
const DEFAULT_BOOLEAN_VALUES = { true: ["true", "t", "yes", "y"], false: ["false", "f", "no", "n"] };
const defaultToBoolean = (value) => {
  if (DEFAULT_BOOLEAN_VALUES.true.includes(String(value).trim().toLowerCase())) {
    return true;
  }
  if (DEFAULT_BOOLEAN_VALUES.false.includes(String(value).trim().toLowerCase())) {
    return false;
  }
  return null;
};
const guessColumnTypes = (columnValuesWithNulls, options = {}) => {
  const { isNull = defaultIsNull, toBoolean = defaultToBoolean } = options;
  const columnValues = columnValuesWithNulls.filter((value) => !isNull(value));
  if (columnValues.length === 0) {
    return "string";
  }
  if (columnValues.every((value) => isBoolean(value, toBoolean))) {
    return "bool";
  }
  if (columnValues.every(isInteger)) {
    return "int";
  }
  if (columnValues.every(isFloat)) {
    return "float";
  }
  if (columnValues.every(isDateTime)) {
    return "datetime";
  }
  if (columnValues.every(isEmail)) {
    return "email";
  }
  if (isGuessableVectorColumn(columnValues)) {
    return "vector";
  }
  if (columnValues.some(isGuessableMultiple)) {
    return "multiple";
  }
  if (columnValues.some((value) => isDataUri(value))) {
    return "file[]";
  }
  if (columnValues.some(isText)) {
    return "text";
  }
  return "string";
};
const coerceValue = async (value, column, options = {}) => {
  const { isNull = defaultIsNull, toBoolean = defaultToBoolean, proxyFunction } = options;
  if (isNull(value)) {
    return { value: null, isError: false };
  }
  switch (column.type) {
    case "string":
    case "text":
    case "link": {
      return { value: String(value), isError: false };
    }
    case "email": {
      return isEmail(value) ? { value: String(value).trim(), isError: false } : { value: null, isError: true };
    }
    case "int": {
      return isInteger(value) || isFloat(value) ? { value: parseInt(String(value), 10), isError: false } : { value: null, isError: true };
    }
    case "float": {
      return isFloat(value) ? { value: parseFloat(String(value)), isError: false } : { value: null, isError: true };
    }
    case "bool": {
      const boolValue = toBoolean(value);
      return { value: boolValue, isError: boolValue === null };
    }
    case "datetime": {
      const date = anyToDate(value);
      return date.invalid ? { value: null, isError: true } : { value: date, isError: false };
    }
    case "vector": {
      if (!isMaybeMultiple(value))
        return { value: null, isError: true };
      const array = parseMultiple(String(value));
      return {
        value: array,
        isError: array?.some((item) => !isFloat(item)) || array?.length !== column.vector?.dimension
      };
    }
    case "multiple": {
      return isMaybeMultiple(value) ? { value: parseMultiple(String(value)), isError: false } : { value: null, isError: true };
    }
    case "file": {
      const file = await parseFile(value.trim(), proxyFunction);
      if (!file)
        return { value: null, isError: true };
      return { value: file, isError: false };
    }
    case "file[]": {
      const items = value.match(/(data:.*?;base64,.*?(?:[;,|]|$))|(https?:\/\/.*?(?:[;,|]|$))|((?:file:\/\/)?.*?(?:[;,|]|$))/g)?.map((item) => item.replace(/[;,|]$/g, ""))?.filter((item) => item !== "") ?? [];
      const files = await Promise.all(items.map((url) => parseFile(url, proxyFunction)));
      const isError = files.some((file) => file === null);
      return { value: compact(files), isError };
    }
    default: {
      return { value: null, isError: true };
    }
  }
};
const fetchFile = async (url) => {
  const response = await fetch(url);
  return await response.blob();
};
const parseFile = async (url, request = fetchFile) => {
  const uri = url.trim();
  try {
    if (uri.startsWith("data:")) {
      const [mediaType, base64Content] = uri.replace("data:", "").split(";base64,");
      return new client.XataFile({ base64Content, mediaType });
    } else if (uri.startsWith("http://") || uri.startsWith("https://")) {
      const blob = await request(url);
      return client.XataFile.fromBlob(blob);
    } else {
      const [fs, path] = await Promise.all(["fs", "path"].map((name) => import(name)));
      const filePath = path.resolve(uri.replace("file://", ""));
      const blob = new Blob([fs.readFileSync(filePath)], { type: "application/octet-stream" });
      return client.XataFile.fromBlob(blob, { name: path.basename(filePath) });
    }
  } catch (error) {
    console.log(error);
    return null;
  }
};
const coerceRows = async (rows, columns, options) => {
  const mapped = [];
  for (const row of rows) {
    const mappedRow = {};
    for (const column of columns) {
      mappedRow[column.name] = await coerceValue(row[column.name], column, options);
    }
    mapped.push(mappedRow);
  }
  return mapped;
};
const guessColumns = (rows, options) => {
  const columnNames = new Set(...rows.map((row) => Object.keys(row)));
  return [...columnNames].map((columnName) => {
    const values = rows.map((row) => row[columnName]);
    const type = columnName === "id" ? "string" : guessColumnTypes(values, options);
    return { name: columnName, type };
  });
};

const arrayToObject = (array) => {
  return Object.fromEntries(array.map((value, index) => [index, value]));
};
const prepareColumns = (columns, values) => {
  return columns.map((column) => {
    switch (column.type) {
      case "vector": {
        const dimension = values[0]?.data?.[column.name]?.length ?? 0;
        return { ...column, vector: { dimension } };
      }
      default:
        return column;
    }
  });
};
const parseJson = async (options, startIndex = 0) => {
  const { data: input, columns: externalColumns, limit } = options;
  const array = Array.isArray(input) ? input : isObject(input) ? [input] : JSON$1.parse(input);
  const arrayUpToLimit = isDefined(limit) ? array.slice(0, limit) : array;
  const columnsGuessed = externalColumns ?? guessColumns(arrayUpToLimit, options);
  const item = await coerceRows(arrayUpToLimit, columnsGuessed, options);
  const data = item.map((row, index) => {
    const original = Array.isArray(arrayUpToLimit[index]) ? arrayToObject(arrayUpToLimit[index]) : arrayUpToLimit[index];
    const errorKeys = Object.entries(row).filter(([_key, value]) => value.isError).map(([key]) => key);
    const [files, data2] = partition(
      Object.entries(row).map(([key, item2]) => [key, item2.value]),
      ([_key, value]) => isXataFile(value) || Array.isArray(value) && value.some(isXataFile)
    );
    return {
      data: Object.fromEntries(data2),
      files: Object.fromEntries(files),
      original,
      index: index + startIndex,
      errorKeys
    };
  });
  const columns = prepareColumns(columnsGuessed, data);
  return { success: true, columns, warnings: [], data };
};

const DEFAULT_CSV_DELIMITERS_TO_GUESS = [",", "	", "|", ";", "", ""];
const stripBom = (string) => {
  if (typeof string !== "string") {
    throw new TypeError(`Expected a string, got ${typeof string}`);
  }
  if (string.charCodeAt(0) === 65279) {
    return string.slice(1);
  }
  return string;
};
const metaToParseMeta = (meta) => ({
  delimiter: meta.delimiter,
  linebreak: meta.linebreak,
  fields: meta.fields
});
const parseCsvOptionsToPapaOptions = (options) => {
  const {
    limit,
    delimiter,
    header = true,
    skipEmptyLines = true,
    delimitersToGuess = DEFAULT_CSV_DELIMITERS_TO_GUESS,
    newline,
    quoteChar = '"',
    escapeChar = '"',
    commentPrefix
  } = options;
  return {
    header,
    skipEmptyLines,
    preview: limit,
    delimiter,
    delimitersToGuess,
    newline,
    quoteChar,
    escapeChar,
    comments: commentPrefix,
    transformHeader(header2) {
      return stripBom(header2);
    }
  };
};
const dataForColumns = (data, columns) => {
  if (!columns) {
    return data;
  }
  return data.map(
    (d) => pick(
      d,
      columns.map((col) => col.name)
    )
  );
};
const papaResultToJson = async ({ data, errors }, options, startIndex = 0) => {
  const parseWarnings = errors.map((error) => error.message);
  const jsonResults = await parseJson(
    {
      ...options,
      data: dataForColumns(data, options.columns)
    },
    startIndex
  );
  return jsonResults.success ? {
    ...jsonResults,
    warnings: [...parseWarnings, ...jsonResults.warnings]
  } : jsonResults;
};

const CHUNK_SIZE = 1024 * 1024 * 10;
const parseCsvStream = async ({ fileStream, parserOptions }) => {
  return new Promise((resolve, reject) => {
    CSV.parse(fileStream, {
      ...parseCsvOptionsToPapaOptions(parserOptions),
      complete: async (papaResults) => {
        const results = await papaResultToJson(papaResults, parserOptions);
        resolve({ results, meta: { estimatedProgress: 1, rowIndex: 0, ...metaToParseMeta(papaResults.meta) } });
      },
      error: (error) => reject(error)
    });
  });
};
const parseCsvStreamBatches = async ({
  fileStream,
  fileSizeBytes,
  parserOptions,
  batchRowCount = 1e3,
  batchSizeMin = 10,
  concurrentBatchMax = 5,
  onBatch = () => new Promise((resolve) => resolve())
}) => {
  let rowCount = 0;
  let lastChunkProcessedRowCount = 0;
  let averageCursorPerRow = 0;
  let chunk = null;
  return new Promise((resolve, reject) => {
    CSV.parse(fileStream, {
      ...parseCsvOptionsToPapaOptions(parserOptions),
      chunkSize: CHUNK_SIZE,
      chunk: async (result, parser) => {
        try {
          if (!chunk) {
            chunk = result;
          } else {
            for (const item of result.data) {
              chunk.data.push(item);
            }
            chunk.meta = result.meta;
            for (const error of result.errors) {
              chunk.errors.push(error);
            }
          }
          const oldRowCount = rowCount;
          rowCount += result.data.length;
          averageCursorPerRow = result.meta.cursor / rowCount;
          if (chunk.data.length >= batchRowCount * batchSizeMin) {
            parser.pause();
            chunk = await processPapaChunk({
              papaChunk: chunk,
              parser,
              parserOptions,
              batchRowCount,
              averageCursorPerRow,
              fileSizeBytes,
              batchSizeMin,
              concurrentBatchMax,
              onBatch,
              startRowIndex: lastChunkProcessedRowCount
            });
            lastChunkProcessedRowCount = oldRowCount;
            parser.resume();
          }
        } catch (error) {
          reject(error);
          parser.abort();
        }
      },
      complete: async () => {
        try {
          if (chunk) {
            await processPapaChunk({
              papaChunk: chunk,
              parserOptions,
              batchRowCount,
              averageCursorPerRow,
              fileSizeBytes,
              batchSizeMin,
              concurrentBatchMax,
              onBatch,
              forceFinish: true,
              startRowIndex: rowCount - chunk.data.length
            });
          }
          resolve();
        } catch (error) {
          reject(error);
        }
      },
      error: (error) => reject(error)
    });
  });
};
const processBatch = async ({
  data,
  errors,
  meta,
  parserOptions,
  parser,
  onBatch,
  fileSizeEstimateBytes,
  startRowIndex
}) => {
  const results = await papaResultToJson({ data, errors, meta }, parserOptions, startRowIndex);
  const estimatedProgress = meta.cursor / fileSizeEstimateBytes;
  try {
    await onBatch(results, { estimatedProgress, rowIndex: startRowIndex, ...metaToParseMeta(meta) });
  } catch (error) {
    parser?.abort();
    throw error;
  }
};
const calcAmountToProcess = (chunk, batchRowCount, forceFinish, batchSizeMin) => {
  if (forceFinish) {
    return chunk.data.length;
  }
  const chunks = Math.floor(chunk.data.length / batchRowCount);
  if (chunks < batchSizeMin) {
    return 0;
  }
  return chunks * batchRowCount;
};
const processPapaChunk = async ({
  papaChunk,
  parser,
  parserOptions,
  batchRowCount,
  averageCursorPerRow,
  fileSizeBytes,
  batchSizeMin,
  concurrentBatchMax,
  onBatch,
  forceFinish = false,
  startRowIndex
}) => {
  const amountToProcess = calcAmountToProcess(papaChunk, batchRowCount, forceFinish, batchSizeMin);
  if (amountToProcess <= 0) {
    return papaChunk;
  }
  const data = papaChunk.data.splice(0, amountToProcess);
  const errors = papaChunk.errors.splice(0, amountToProcess);
  const batches = chunkArray(data, batchRowCount);
  const promises = batches.map((batchData, index) => {
    const rowsSoFar = batchData.length + batchRowCount * index;
    const rowsFromEnd = data.length - rowsSoFar;
    const estimatedCursor = Math.floor(papaChunk.meta.cursor - averageCursorPerRow * rowsFromEnd);
    const fileSizeEstimateBytes = isDefined(parserOptions.limit) ? averageCursorPerRow * parserOptions.limit : fileSizeBytes;
    return () => processBatch({
      data: batchData,
      errors,
      meta: { ...papaChunk.meta, cursor: estimatedCursor },
      parserOptions,
      parser,
      onBatch,
      fileSizeEstimateBytes,
      startRowIndex: startRowIndex + batchRowCount * index
    });
  });
  const queue = new PQueue({ concurrency: concurrentBatchMax, carryoverConcurrencyCount: true });
  await queue.addAll(promises);
  return papaChunk;
};

const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

const importBatch = async (location, options, pluginOptions, errors, maxRetries = 10, retries = 0) => {
  const { batchRows } = options;
  const operations = batchRows.map((row) => {
    return {
      insert: {
        table: options.table,
        record: row
      }
    };
  });
  try {
    const { results } = await client.branchTransaction({
      ...pluginOptions,
      pathParams: {
        workspace: location.workspace,
        region: location.region,
        dbBranchName: `${location.database}:${location.branch}`,
        // @ts-expect-error For some reason, database is required...
        database: location.database
      },
      body: { operations }
    });
    const ids = results.map((r) => "id" in r ? r.id : null);
    return { ids, errors };
  } catch (error) {
    if (error.errors) {
      const rowErrors = error.errors.filter((e) => e.index !== void 0);
      const errorRowIndexes = rowErrors.map((e) => e.index);
      const rowsToRetry = batchRows.filter((_row, index) => !errorRowIndexes.includes(index));
      const errors2 = rowErrors.map((e) => ({ row: batchRows[e.index], error: e.message, index: e.index }));
      return importBatch(location, { ...options, batchRows: rowsToRetry }, pluginOptions, errors2, maxRetries, retries);
    }
    if (retries < maxRetries) {
      await delay(1e3 * 2 ** retries);
      return importBatch(location, options, pluginOptions, errors, maxRetries, retries + 1);
    }
    throw error;
  }
};
const importFiles = async (location, options, pluginOptions) => {
  const { workspace, database, region, branch } = location;
  const { table, ids, files } = options;
  for (const index in files) {
    const row = files[index];
    const record = ids[index];
    for (const [columnName, value] of Object.entries(row)) {
      const files2 = Array.isArray(value) ? value : [value];
      for (const file of files2) {
        try {
          await client.putFile({
            ...pluginOptions,
            pathParams: {
              workspace,
              // @ts-expect-error For some reason we need to send it
              database,
              branch,
              region,
              tableName: table,
              recordId: record ?? "",
              columnName: columnName.trim()
            },
            body: file.toBlob(),
            headers: { "Content-Type": file.mediaType ?? "application/octet-stream" }
          });
        } catch (error) {
          console.log(error);
        }
      }
    }
  }
};

class XataImportPlugin extends client.XataPlugin {
  build(pluginOptions) {
    return {
      parseCsvStream,
      parseCsvStreamBatches,
      importBatch: (location, options) => importBatch(location, options, pluginOptions),
      importFiles: (location, options) => importFiles(location, options, pluginOptions)
    };
  }
}

function generateRandomData(table, size) {
  const records = [];
  for (let index = 0; index < size; index++) {
    records.push(randomRecord(table.columns));
  }
  return records;
}
function randomRecord(columns) {
  const record = {};
  for (const column of columns) {
    record[column.name] = randomData(column);
  }
  return record;
}
function randomData(column) {
  switch (column.type) {
    case "text":
      return faker.fakerEN.lorem.paragraphs(rand(2, 3));
    case "email":
      return faker.fakerEN.internet.email({ provider: "acme.pets" });
    case "int":
      return rand(1, 100);
    case "float":
      return rand(1, 1e4) / rand(1, 100);
    case "bool":
      return rand(0, 1) === 1;
    case "multiple":
      return faker.fakerEN.word.words(rand(1, 3)).split(" ");
    case "string":
      return randomString(column.name);
    case "datetime":
      return faker.fakerEN.date.recent({ days: rand(1, 10) });
    default:
      return void 0;
  }
}
function rand(min, max) {
  return Math.floor(Math.random() * (max - min) + min);
}
const generators = {
  city: () => faker.fakerEN.location.city(),
  country: () => faker.fakerEN.location.country(),
  county: () => faker.fakerEN.location.county(),
  state: () => faker.fakerEN.location.state(),
  street: () => faker.fakerEN.location.street(),
  timezone: () => faker.fakerEN.location.timeZone(),
  tz: () => faker.fakerEN.location.timeZone(),
  zipcode: () => faker.fakerEN.location.zipCode(),
  zip: () => faker.fakerEN.location.zipCode(),
  department: () => faker.fakerEN.commerce.department(),
  product: () => faker.fakerEN.commerce.product(),
  company: () => faker.fakerEN.company.name(),
  firstName: () => faker.fakerEN.person.firstName(),
  lastName: () => faker.fakerEN.person.lastName(),
  phone: () => faker.fakerEN.phone.number("501-###-###")
};
function randomString(columnName) {
  const gen = generators[columnName.toLowerCase()];
  if (gen)
    return gen();
  return faker.fakerEN.word.words(2);
}

const importColumnTypes = zod.z.enum([
  "bool",
  "int",
  "float",
  "string",
  "text",
  "email",
  "datetime",
  "link",
  "multiple",
  "file",
  "file[]",
  "vector"
]);

exports.DEFAULT_CSV_DELIMITERS_TO_GUESS = DEFAULT_CSV_DELIMITERS_TO_GUESS;
exports.XataImportPlugin = XataImportPlugin;
exports.generateRandomData = generateRandomData;
exports.guessColumnTypes = guessColumnTypes;
exports.importColumnTypes = importColumnTypes;
exports.isValidEmail = isValidEmail;
exports.parseCsvStream = parseCsvStream;
exports.parseCsvStreamBatches = parseCsvStreamBatches;
//# sourceMappingURL=index.cjs.map
